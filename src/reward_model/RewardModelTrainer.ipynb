{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa081f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, random, numpy as np\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, Any, Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de28fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "CUR_DIR = Path.cwd()\n",
    "SRC_DIR = CUR_DIR.parent\n",
    "\n",
    "DATA_DIR = SRC_DIR / \"data\" / \"processed\"\n",
    "PAIRS_PATH = DATA_DIR / \"preference_pairs.json\"\n",
    "#TEST_QNA_PATH = DATA_DIR / \"test_qna_with_confidence.json\"\n",
    "\n",
    "TRAIN_PATH  = DATA_DIR / \"preference_pairs_train.json\"\n",
    "VAL_PATH   = DATA_DIR / \"preference_pairs_val.json\"\n",
    "\n",
    "CKPT_DIR = CUR_DIR / \"checkpoints\"\n",
    "METRIC_DIR = CUR_DIR / \"metrics\"\n",
    "\n",
    "DROP_WEAK = False # set True later if want cleaner supervision\n",
    "\n",
    "TRAIN_RATIO = 0.9\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.0\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2264741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [DATA_DIR, CKPT_DIR, METRIC_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _read_json(p: Path):\n",
    "    return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _write_json(obj, p: Path):\n",
    "    p.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    print(f\"[saved] {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b4ef0",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3eed9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_preference_pairs(\n",
    "    pairs_path: Path,\n",
    "    out_dir: Path,\n",
    "    train_ratio: float = 0.9,\n",
    "    val_ratio: float = 0.1,\n",
    "    test_ratio: float = 0.0,\n",
    "    seed: int = 42,\n",
    "    drop_weak: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Split preference_pairs.json into train/val(/test) without question leakage.\n",
    "\n",
    "    Args:\n",
    "        pairs_path: path to preference_pairs.json\n",
    "        out_dir: directory to write split files\n",
    "        train_ratio, val_ratio, test_ratio: must sum to 1.0 (test optional)\n",
    "        seed: RNG seed for reproducibility\n",
    "        drop_weak: if True, drops pairs with score_difference==0 and pairs where both ratings == 1\n",
    "\n",
    "    Writes:\n",
    "        preference_pairs.train.json\n",
    "        preference_pairs.val.json\n",
    "        (optional) preference_pairs.test.json\n",
    "        preference_pairs_split_stats.json\n",
    "\n",
    "    Returns:\n",
    "        stats dict with counts, distributions, and dropped info.\n",
    "    \"\"\"\n",
    "    assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _rating_score(ans: Dict[str, Any]) -> int:\n",
    "        # Prefer explicit numeric 'score'; fallback parse from 'rating' like \"3-Incomplete\"\n",
    "        if \"score\" in ans and ans[\"score\"] is not None:\n",
    "            return int(ans[\"score\"])\n",
    "        r = ans.get(\"rating\", \"\")\n",
    "        return int(r[0]) if isinstance(r, str) and r[:1].isdigit() else -1  # -1 if unknown\n",
    "\n",
    "    # Load data\n",
    "    pairs = _read_json(pairs_path)\n",
    "\n",
    "    # Optional filtering\n",
    "    dropped = {\"score_diff_zero\": 0, \"both_score1\": 0} # counts how many pairs were removed for each reason\n",
    "    clean = []\n",
    "    if drop_weak:\n",
    "        for ex in pairs: # ex = preference pair dict\n",
    "            if ex.get(\"score_difference\", None) == 0:\n",
    "                dropped[\"score_diff_zero\"] += 1\n",
    "                continue\n",
    "            sp = _rating_score(ex.get(\"preferred_answer\", {}))\n",
    "            sr = _rating_score(ex.get(\"rejected_answer\", {}))\n",
    "            if sp == 1 and sr == 1:\n",
    "                dropped[\"both_score1\"] += 1\n",
    "                continue\n",
    "            clean.append(ex) # only store if passes filters\n",
    "    else:\n",
    "        clean = pairs\n",
    "\n",
    "    # Group by question_id (no leakage across splits)\n",
    "    by_qid = defaultdict(list)\n",
    "    for ex in clean:\n",
    "        qid = ex[\"question_id\"]\n",
    "        by_qid[qid].append(ex)\n",
    "\n",
    "    qids = list(by_qid.keys())\n",
    "    random.seed(seed)\n",
    "    random.shuffle(qids)\n",
    "\n",
    "    # Stratify by risk level (keeps similar risk mix across splits)\n",
    "    def majority_risk(items):\n",
    "        return Counter(e.get(\"risk_level\", \"UNKNOWN\") for e in items).most_common(1)[0][0]\n",
    "\n",
    "    risk_to_qids = defaultdict(list)\n",
    "    for qid in qids:\n",
    "        risk_to_qids[majority_risk(by_qid[qid])].append(qid)\n",
    "\n",
    "    train_qids, val_qids, test_qids = set(), set(), set()\n",
    "    for _, bucket in risk_to_qids.items():\n",
    "        random.shuffle(bucket)\n",
    "        n = len(bucket)\n",
    "        n_train = int(round(n * train_ratio))\n",
    "        n_val   = int(round(n * val_ratio))\n",
    "        # ensure total fits by assigning remainder to test\n",
    "        n_test  = n - n_train - n_val\n",
    "        train_qids.update(bucket[:n_train])\n",
    "        val_qids.update(bucket[n_train:n_train+n_val])\n",
    "        test_qids.update(bucket[n_train+n_val:])\n",
    "\n",
    "    # Materialise splits\n",
    "    train_pairs = [e for q in train_qids for e in by_qid[q]]\n",
    "    val_pairs   = [e for q in val_qids   for e in by_qid[q]]\n",
    "    test_pairs  = [e for q in test_qids  for e in by_qid[q]] if test_ratio > 0 else []\n",
    "\n",
    "    # Save\n",
    "    _write_json(train_pairs, out_dir / \"preference_pairs_train.json\")\n",
    "    _write_json(val_pairs,   out_dir / \"preference_pairs_val.json\")\n",
    "    if test_ratio > 0:\n",
    "        _write_json(test_pairs, out_dir / \"preference_pairs_test.json\")\n",
    "\n",
    "    def _dist(lst):\n",
    "        return dict(Counter(e.get(\"risk_level\", \"UNKNOWN\") for e in lst))\n",
    "\n",
    "    stats = {\n",
    "        \"seed\": seed,\n",
    "        \"drop_weak\": drop_weak,\n",
    "        \"dropped\": dropped,\n",
    "        \"counts\": {\n",
    "            \"train\": len(train_pairs),\n",
    "            \"val\":   len(val_pairs),\n",
    "            \"test\":  len(test_pairs),\n",
    "        },\n",
    "        \"unique_qids\": {\n",
    "            \"train\": len(train_qids),\n",
    "            \"val\":   len(val_qids),\n",
    "            \"test\":  len(test_qids),\n",
    "        },\n",
    "        \"risk_dist\": {\n",
    "            \"train\": _dist(train_pairs),\n",
    "            \"val\":   _dist(val_pairs),\n",
    "            \"test\":  _dist(test_pairs),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    _write_json(stats, out_dir / \"preference_pairs_split_stats.json\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6da042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] c:\\Users\\Crescent\\OneDrive\\Personal\\my files\\3. nus\\Y3S1\\DSA4213 Natural Language Processing for Data Science\\Project\\GitHub\\SelfTraining-Reward-MedQA\\src\\data\\processed\\preference_pairs_train.json\n",
      "[saved] c:\\Users\\Crescent\\OneDrive\\Personal\\my files\\3. nus\\Y3S1\\DSA4213 Natural Language Processing for Data Science\\Project\\GitHub\\SelfTraining-Reward-MedQA\\src\\data\\processed\\preference_pairs_val.json\n",
      "[saved] c:\\Users\\Crescent\\OneDrive\\Personal\\my files\\3. nus\\Y3S1\\DSA4213 Natural Language Processing for Data Science\\Project\\GitHub\\SelfTraining-Reward-MedQA\\src\\data\\processed\\preference_pairs_split_stats.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'drop_weak': False,\n",
       " 'dropped': {'score_diff_zero': 0, 'both_score1': 0},\n",
       " 'counts': {'train': 27775, 'val': 3327, 'test': 0},\n",
       " 'unique_qids': {'train': 92, 'val': 11, 'test': 0},\n",
       " 'risk_dist': {'train': {'Low Risk': 6389,\n",
       "   'High Risk': 11715,\n",
       "   'Medium Risk': 9671},\n",
       "  'val': {'High Risk': 1833, 'Medium Risk': 878, 'Low Risk': 616},\n",
       "  'test': {}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = split_preference_pairs(\n",
    "    pairs_path = PAIRS_PATH,\n",
    "    out_dir    = DATA_DIR,\n",
    "    train_ratio= TRAIN_RATIO,     # 90/10 train/val\n",
    "    val_ratio  = VAL_RATIO,\n",
    "    test_ratio = TEST_RATIO,     # set to 0.1 if want a test split too\n",
    "    seed       = SEED,\n",
    "    drop_weak  = DROP_WEAK # change to True later if want cleaner pairs\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cea4c8",
   "metadata": {},
   "source": [
    "# Load splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0f3ddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27775, 3327)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH  = DATA_DIR / \"preference_pairs_train.json\"\n",
    "VAL_PATH   = DATA_DIR / \"preference_pairs_val.json\"\n",
    "\n",
    "train_pairs = _read_json(TRAIN_PATH)\n",
    "val_pairs = _read_json(VAL_PATH)\n",
    "len(train_pairs), len(val_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d181926",
   "metadata": {},
   "source": [
    "# Dataset + Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "471443ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "BETA = 3.0  # scales confidence_penalty into a sample weight\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18f49faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer (ensure PAD exists)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a2ac96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13888, 1664)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_input(q, a):\n",
    "    return f\"Question:\\n{q}\\n\\nAnswer:\\n{a}\"\n",
    "\n",
    "# Dataset and collate\n",
    "class PrefPairDataset(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        ex = self.items[i]\n",
    "        x_pos = build_input(ex[\"question_text\"], ex[\"preferred_answer\"][\"answer_text\"])\n",
    "        x_neg = build_input(ex[\"question_text\"], ex[\"rejected_answer\"][\"answer_text\"])\n",
    "        pos = tokenizer(x_pos, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        neg = tokenizer(x_neg, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        w = 1.0 + BETA * float(ex.get(\"confidence_penalty\", 0.0))\n",
    "        return {\"pos\": pos, \"neg\": neg, \"weight\": torch.tensor(w, dtype=torch.float)}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    def stack(side):\n",
    "        ids  = [b[side][\"input_ids\"].squeeze(0) for b in batch]\n",
    "        attn = [b[side][\"attention_mask\"].squeeze(0) for b in batch]\n",
    "        ids  = torch.nn.utils.rnn.pad_sequence(ids,  batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        attn = torch.nn.utils.rnn.pad_sequence(attn, batch_first=True, padding_value=0)\n",
    "        return {\"input_ids\": ids, \"attention_mask\": attn}\n",
    "    weights = torch.stack([b[\"weight\"] for b in batch])\n",
    "    return {\"pos\": stack(\"pos\"), \"neg\": stack(\"neg\"), \"weight\": weights}\n",
    "\n",
    "# build loaders\n",
    "train_loader = DataLoader(PrefPairDataset(train_pairs), batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(PrefPairDataset(val_pairs),   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "088496b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.32s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: CPU\n",
      "Loaded: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Reward model (1 scalar output)\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32 # CPU requires float32\n",
    "device_map = \"auto\" if torch.cuda.is_available() else None\n",
    "max_memory = {0: \"13GB\"} if torch.cuda.is_available() else None\n",
    "\n",
    "reward_model  = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device_map,\n",
    "    low_cpu_mem_usage=True,\n",
    "    max_memory=max_memory\n",
    ")\n",
    "\n",
    "# align special tokens / training toggles\n",
    "reward_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "reward_model.config.eos_token_id = tokenizer.eos_token_id\n",
    "reward_model.config.bos_token_id = getattr(tokenizer, \"bos_token_id\", tokenizer.eos_token_id)\n",
    "reward_model.config.use_cache = False  # safer during training\n",
    "\n",
    "print(\"Device:\", \"CUDA\" if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Loaded:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27bd1b",
   "metadata": {},
   "source": [
    "## check model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27f47da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer (path)                                                 Type                   Output Shape                      Param #  Trainable\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "model.embed_tokens                                           Embedding              (1, 64, 3072)                 394,002,432 394,002,432\n",
      "model.rotary_emb                                             LlamaRotaryEmbedding   [(1, 64, 128), (1, 64, 128)]            0          0\n",
      "model.layers.0.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.0.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.0.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.0.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.0.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.0.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.0.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.0.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.0.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.0.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.1.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.1.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.1.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.1.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.1.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.1.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.1.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.1.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.1.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.1.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.2.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.2.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.2.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.2.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.2.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.2.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.2.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.2.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.2.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.2.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.3.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.3.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.3.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.3.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.3.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.3.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.3.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.3.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.3.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.3.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.4.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.4.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.4.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.4.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.4.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.4.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.4.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.4.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.4.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.4.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.5.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.5.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.5.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.5.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.5.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.5.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.5.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.5.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.5.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.5.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.6.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.6.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.6.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.6.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.6.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.6.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.6.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.6.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.6.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.6.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.7.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.7.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.7.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.7.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.7.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.7.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.7.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.7.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.7.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.7.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.8.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.8.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.8.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.8.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.8.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.8.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.8.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.8.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.8.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.8.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.9.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.9.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.9.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.9.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.9.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.9.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.9.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.9.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.9.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.9.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.10.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.10.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.10.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.10.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.10.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.10.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.10.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.10.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.10.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.10.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.11.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.11.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.11.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.11.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.11.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.11.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.11.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.11.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.11.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.11.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.12.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.12.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.12.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.12.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.12.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.12.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.12.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.12.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.12.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.12.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.13.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.13.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.13.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.13.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.13.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.13.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.13.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.13.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.13.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.13.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.14.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.14.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.14.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.14.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.14.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.14.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.14.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.14.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.14.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.14.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.15.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.15.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.15.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.15.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.15.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.15.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.15.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.15.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.15.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.15.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.16.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.16.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.16.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.16.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.16.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.16.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.16.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.16.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.16.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.16.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.17.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.17.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.17.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.17.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.17.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.17.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.17.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.17.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.17.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.17.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.18.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.18.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.18.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.18.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.18.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.18.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.18.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.18.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.18.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.18.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.19.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.19.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.19.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.19.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.19.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.19.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.19.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.19.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.19.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.19.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.20.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.20.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.20.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.20.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.20.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.20.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.20.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.20.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.20.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.20.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.21.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.21.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.21.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.21.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.21.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.21.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.21.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.21.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.21.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.21.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.22.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.22.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.22.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.22.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.22.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.22.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.22.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.22.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.22.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.22.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.23.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.23.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.23.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.23.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.23.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.23.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.23.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.23.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.23.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.23.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.24.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.24.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.24.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.24.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.24.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.24.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.24.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.24.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.24.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.24.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.25.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.25.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.25.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.25.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.25.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.25.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.25.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.25.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.25.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.25.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.26.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.26.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.26.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.26.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.26.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.26.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.26.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.26.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.26.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.26.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.27.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.27.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.27.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.27.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.27.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.27.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.27.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.27.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.27.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.27.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.norm                                                   LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "score                                                        Linear                 (1, 64, 1)                          3,072      3,072\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total params:     3,212,752,896  (~12255.7 MB at float32)\n",
      "Trainable params: 3,212,752,896  (~12255.7 MB)\n",
      "Frozen params:    0  (~0.0 MB)\n",
      "Seq len used for summary: 64, batch size: 1\n"
     ]
    }
   ],
   "source": [
    "# ===== Keras-like summary for HF models =====\n",
    "import torch, math\n",
    "from collections import OrderedDict\n",
    "\n",
    "def _num_params(module):\n",
    "    total = sum(p.numel() for p in module.parameters(recurse=False))\n",
    "    train = sum(p.numel() for p in module.parameters(recurse=False) if p.requires_grad)\n",
    "    return total, train\n",
    "\n",
    "def _shape_str(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return tuple(x.shape)\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        # show first few shapes if it's a tuple/list\n",
    "        parts = []\n",
    "        for i, it in enumerate(x[:3]):\n",
    "            if isinstance(it, torch.Tensor):\n",
    "                parts.append(str(tuple(it.shape)))\n",
    "            else:\n",
    "                parts.append(type(it).__name__)\n",
    "        if len(x) > 3:\n",
    "            parts.append(\"...\")\n",
    "        return \"[\" + \", \".join(parts) + \"]\"\n",
    "    return type(x).__name__\n",
    "\n",
    "def model_summary(model, tokenizer, seq_len=64, verbose=True):\n",
    "    \"\"\"\n",
    "    Prints a Keras-like table:\n",
    "      Layer (path) | Type | Output Shape | Param # (trainable)\n",
    "    Uses a dummy forward pass with batch_size=1 and input length = seq_len.\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    dtype  = next(model.parameters()).dtype\n",
    "    bytes_per = 2 if dtype in (torch.float16, torch.bfloat16) else 4\n",
    "\n",
    "    # 1) Prepare a tiny dummy batch\n",
    "    with torch.no_grad():\n",
    "        toks = tokenizer(\"dummy\", return_tensors=\"pt\", add_special_tokens=True)\n",
    "        # expand to desired seq_len (pad tokens)\n",
    "        input_ids = torch.full((1, seq_len), fill_value=tokenizer.pad_token_id, dtype=torch.long)\n",
    "        attn_mask = torch.zeros((1, seq_len), dtype=torch.long)\n",
    "        # put some non-pad tokens at the start\n",
    "        L = min(toks[\"input_ids\"].shape[1], seq_len)\n",
    "        input_ids[:, :L] = toks[\"input_ids\"][:, :L]\n",
    "        attn_mask[:, :L] = 1\n",
    "        batch = {\"input_ids\": input_ids.to(device), \"attention_mask\": attn_mask.to(device)}\n",
    "\n",
    "    # 2) Collect module info (param counts) and register forward hooks for output shapes\n",
    "    names = {m: n for n, m in model.named_modules()}  # module -> qualified name\n",
    "    layer_infos = OrderedDict()      # preserve execution order\n",
    "    handles = []\n",
    "\n",
    "    def hook(module, inputs, outputs):\n",
    "        name = names.get(module, module.__class__.__name__)\n",
    "        if name == \"\": name = module.__class__.__name__\n",
    "        if name not in layer_infos:\n",
    "            p_total, p_train = _num_params(module)\n",
    "            layer_infos[name] = {\n",
    "                \"type\": module.__class__.__name__,\n",
    "                \"params\": p_total,\n",
    "                \"trainable\": p_train,\n",
    "                \"out\": _shape_str(outputs),\n",
    "            }\n",
    "\n",
    "    # only hook leaf modules to avoid noisy duplicates\n",
    "    for m in model.modules():\n",
    "        is_leaf = len(list(m.children())) == 0\n",
    "        if is_leaf:\n",
    "            try:\n",
    "                handles.append(m.register_forward_hook(hook))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 3) Forward pass (to populate shapes)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**batch)\n",
    "\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "\n",
    "    # 4) Print table\n",
    "    total_params = sum(v[\"params\"] for v in layer_infos.values())\n",
    "    train_params = sum(v[\"trainable\"] for v in layer_infos.values())\n",
    "    frozen_params = total_params - train_params\n",
    "    total_mb   = (total_params * bytes_per) / (1024**2)\n",
    "    train_mb   = (train_params * bytes_per) / (1024**2)\n",
    "    frozen_mb  = (frozen_params * bytes_per) / (1024**2)\n",
    "\n",
    "    header = f\"{'Layer (path)':60} {'Type':22} {'Output Shape':28} {'Param #':>12} {'Trainable':>10}\"\n",
    "    line   = \"-\" * len(header)\n",
    "    if verbose:\n",
    "        print(header)\n",
    "        print(line)\n",
    "        for name, info in layer_infos.items():\n",
    "            print(f\"{name:60} {info['type']:22} {str(info['out'])[:28]:28} {info['params']:12,} {info['trainable']:10,}\")\n",
    "        print(line)\n",
    "        print(f\"Total params:     {total_params:,}  (~{total_mb:.1f} MB at {str(dtype).replace('torch.','')})\")\n",
    "        print(f\"Trainable params: {train_params:,}  (~{train_mb:.1f} MB)\")\n",
    "        print(f\"Frozen params:    {frozen_params:,}  (~{frozen_mb:.1f} MB)\")\n",
    "        print(f\"Seq len used for summary: {seq_len}, batch size: 1\")\n",
    "\n",
    "    # 5) Return a dict if you want to use programmatically\n",
    "    return {\n",
    "        \"layers\": layer_infos,\n",
    "        \"totals\": {\n",
    "            \"total_params\": total_params,\n",
    "            \"trainable_params\": train_params,\n",
    "            \"frozen_params\": frozen_params,\n",
    "            \"dtype\": str(dtype),\n",
    "            \"mb_total\": total_mb,\n",
    "            \"mb_trainable\": train_mb,\n",
    "            \"mb_frozen\": frozen_mb,\n",
    "            \"bytes_per_param\": bytes_per,\n",
    "            \"seq_len\": seq_len,\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ---- run it\n",
    "_ = model_summary(reward_model, tokenizer, seq_len=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64d09b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:      3,212,752,896  (~12255.7 MB)\n",
      "Trainable params:  3,212,752,896  (~12255.7 MB)\n",
      "Frozen params:     0  (~0.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# ===== Model introspection (counts, layers, arch) =====\n",
    "\n",
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable, (total-trainable)\n",
    "\n",
    "def human_mb(n_params):  # params → MB assuming 4 bytes/param for fp32, ~2 bytes for fp16\n",
    "    bytes_per = 2 if next(reward_model.parameters()).dtype in (torch.float16, torch.bfloat16) else 4\n",
    "    return (n_params * bytes_per) / (1024**2)\n",
    "\n",
    "total, trainable, frozen = count_params(reward_model)\n",
    "print(f\"Total params:      {total:,}  (~{human_mb(total):.1f} MB)\")\n",
    "print(f\"Trainable params:  {trainable:,}  (~{human_mb(trainable):.1f} MB)\")\n",
    "print(f\"Frozen params:     {frozen:,}  (~{human_mb(frozen):.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97106c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top trainable layers (name → #params):\n",
      "  model.embed_tokens.weight                                    394,002,432\n",
      "  model.layers.0.mlp.gate_proj.weight                          25,165,824\n",
      "  model.layers.0.mlp.up_proj.weight                            25,165,824\n",
      "  model.layers.0.mlp.down_proj.weight                          25,165,824\n",
      "  model.layers.1.mlp.gate_proj.weight                          25,165,824\n",
      "  model.layers.1.mlp.up_proj.weight                            25,165,824\n",
      "  model.layers.1.mlp.down_proj.weight                          25,165,824\n",
      "  model.layers.2.mlp.gate_proj.weight                          25,165,824\n",
      "  model.layers.2.mlp.up_proj.weight                            25,165,824\n",
      "  model.layers.2.mlp.down_proj.weight                          25,165,824\n",
      "  model.layers.3.mlp.gate_proj.weight                          25,165,824\n",
      "  model.layers.3.mlp.up_proj.weight                            25,165,824\n",
      "  model.layers.3.mlp.down_proj.weight                          25,165,824\n",
      "  model.layers.4.mlp.gate_proj.weight                          25,165,824\n",
      "  model.layers.4.mlp.up_proj.weight                            25,165,824\n",
      "  model.layers.4.mlp.down_proj.weight                          25,165,824\n",
      "  model.layers.5.mlp.gate_proj.weight                          25,165,824\n",
      "  model.layers.5.mlp.up_proj.weight                            25,165,824\n",
      "  model.layers.5.mlp.down_proj.weight                          25,165,824\n",
      "  model.layers.6.mlp.gate_proj.weight                          25,165,824\n"
     ]
    }
   ],
   "source": [
    "# List trainable layers with param counts (top-N largest first)\n",
    "train_layers = []\n",
    "for n, p in reward_model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        train_layers.append((n, p.numel()))\n",
    "train_layers.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop trainable layers (name → #params):\")\n",
    "for n, sz in train_layers[:20]:  # print top 20 to keep it short\n",
    "    print(f\"  {n:60s} {sz:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9971f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification head (reward scalar) weight shape: (1, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Show the classification head shape\n",
    "if hasattr(reward_model, \"score\"):\n",
    "    print(\"\\nClassification head (reward scalar) weight shape:\", tuple(reward_model.score.weight.shape))\n",
    "elif hasattr(reward_model, \"classifier\"):\n",
    "    print(\"\\nClassification head (reward scalar) weight shape:\", tuple(reward_model.classifier.weight.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4402890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-level modules:\n",
      "  - model: LlamaModel\n",
      "  - score: Linear\n"
     ]
    }
   ],
   "source": [
    "# Short architecture sketch (top-level only)\n",
    "print(\"\\nTop-level modules:\")\n",
    "for name, module in reward_model.named_children():\n",
    "    print(f\"  - {name}: {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0259ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OPTIONAL: freeze/unfreeze helpers =====\n",
    "# Example: freeze all base layers, train only the classification head\n",
    "def freeze_all_but_head(m):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False\n",
    "    # common head names: 'score' (HF seq-classification), else 'classifier'\n",
    "    head = getattr(m, \"score\", None) or getattr(m, \"classifier\", None)\n",
    "    if head is not None:\n",
    "        for p in head.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "# Example usage:\n",
    "# freeze_all_but_head(reward_model)\n",
    "# print(\"After freezing:\")\n",
    "# total, trainable, frozen = count_params(reward_model)\n",
    "# print(f\"Trainable params:  {trainable:,}  (~{human_mb(trainable):.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e415b8c",
   "metadata": {},
   "source": [
    "# Training step (pairwise Bradley-Terry loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5989d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np, math, json\n",
    "\n",
    "def step_batch(model, batch):\n",
    "    for side in (\"pos\",\"neg\"):\n",
    "        for k in batch[side]:\n",
    "            batch[side][k] = batch[side][k].to(model.device)\n",
    "    w = batch[\"weight\"].to(model.device)\n",
    "\n",
    "    r_pos = model(**batch[\"pos\"]).logits.squeeze(-1)  # (B,)\n",
    "    r_neg = model(**batch[\"neg\"]).logits.squeeze(-1)\n",
    "    delta = r_pos - r_neg\n",
    "    loss_core = -torch.log(torch.sigmoid(delta) + 1e-8)   # pairwise logistic\n",
    "    loss = (w * loss_core).mean()\n",
    "    return loss, delta.detach().cpu()\n",
    "\n",
    "optim = AdamW(reward_model.parameters(), lr=2e-5)\n",
    "EPOCHS = 5\n",
    "GRAD_CLIP = 1.0\n",
    "best_val = -1.0\n",
    "best_path = CKPT_DIR / \"best\"\n",
    "\n",
    "def save_ckpt(model, sub=\"epoch\"): # sub: subdirectory name\n",
    "    out = CKPT_DIR / sub\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    tokenizer.save_pretrained(out); model.save_pretrained(out)\n",
    "    print(f\"[saved] {out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148c6f2",
   "metadata": {},
   "source": [
    "# Validation (pairwise accuracy + ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b80c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, bins=10):\n",
    "    model.eval()\n",
    "    probs, corrects = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            _, delta = step_batch(model, batch)\n",
    "            p = torch.sigmoid(delta).numpy()\n",
    "            c = (delta.numpy() > 0).astype(np.float32)\n",
    "            probs.extend(p.tolist()); corrects.extend(c.tolist())\n",
    "\n",
    "    probs = np.array(probs); corrects = np.array(corrects)\n",
    "    acc = float(corrects.mean())\n",
    "\n",
    "    # ECE (Expected Calibration Error)\n",
    "    edges = np.linspace(0,1,bins+1)\n",
    "    ece = 0.0\n",
    "    for i in range(bins):\n",
    "        m = (probs >= edges[i]) & (probs < edges[i+1])\n",
    "        if m.any():\n",
    "            ece += abs(corrects[m].mean() - probs[m].mean()) * (m.sum()/len(probs))\n",
    "    return {\"pairwise_accuracy\": acc, \"ece\": float(ece)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e0804",
   "metadata": {},
   "source": [
    "# Train loop + save metrics & best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c56b02f",
   "metadata": {},
   "source": [
    "## Lightweight logger (JSONL for steps, JSON for epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "799432a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_DIR = METRIC_DIR  # reuse your metrics/ folder\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_LOG = LOG_DIR / \"train_steps.jsonl\"         # per-step loss\n",
    "VAL_EPOCH_LOG = LOG_DIR / \"val_epochs.jsonl\"      # per-epoch metrics\n",
    "VAL_DELTAS_DIR = LOG_DIR / \"val_deltas\"           # per-epoch margins for histogram\n",
    "VAL_DELTAS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def log_train_step(step:int, loss:float, epoch:int):\n",
    "    with TRAIN_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\"ts\": time.time(), \"step\": step, \"epoch\": epoch, \"loss\": float(loss)}) + \"\\n\")\n",
    "\n",
    "def log_val_epoch(epoch:int, metrics:dict):\n",
    "    rec = {\"ts\": time.time(), \"epoch\": epoch, **metrics}\n",
    "    with VAL_EPOCH_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "def dump_val_deltas(epoch:int, deltas:list[float]):\n",
    "    out = VAL_DELTAS_DIR / f\"deltas_epoch{epoch:02d}.json\"\n",
    "    out.write_text(json.dumps({\"epoch\": epoch, \"deltas\": deltas}), encoding=\"utf-8\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7f3f4",
   "metadata": {},
   "source": [
    "## model training, record train loss & store val deltas each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5117aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(d: dict, name: str):\n",
    "    p = METRIC_DIR / name\n",
    "    p.write_text(json.dumps(d, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"[saved] {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6832b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1:   0%|          | 0/13888 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1:   0%|          | 0/13888 [02:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m use_cuda\n\u001b[0;32m     19\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext())  \u001b[38;5;66;03m# disable on CPU\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[1;32m---> 21\u001b[0m     loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mstep_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# returns (loss, delta_cpu)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# backprop with gradient scaling\u001b[39;00m\n\u001b[0;32m     24\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m, in \u001b[0;36mstep_batch\u001b[1;34m(model, batch)\u001b[0m\n\u001b[0;32m      8\u001b[0m         batch[side][k] \u001b[38;5;241m=\u001b[39m batch[side][k]\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      9\u001b[0m w \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 11\u001b[0m r_pos \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B,)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m r_neg \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m delta \u001b[38;5;241m=\u001b[39m r_pos \u001b[38;5;241m-\u001b[39m r_neg\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:959\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 959\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    961\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_layers.py:123\u001b[0m, in \u001b[0;36mGenericForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SequenceClassifierOutputWithPast:\n\u001b[1;32m--> 123\u001b[0m     transformer_outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prefix)(\n\u001b[0;32m    124\u001b[0m         input_ids,\n\u001b[0;32m    125\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    126\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    127\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    128\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    129\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    131\u001b[0m     )\n\u001b[0;32m    132\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    133\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:1083\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m                 module\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m make_capture_wrapper(module, original_forward, key, specs\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   1081\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m-> 1083\u001b[0m outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:390\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[1;32m--> 390\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    391\u001b[0m         hidden_states,\n\u001b[0;32m    392\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    393\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    394\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    395\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    396\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[0;32m    400\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[0;32m    402\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    403\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    404\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_layers.py:93\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:289\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m hidden_states, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[0;32m    290\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    291\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    292\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    293\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[0;32m    294\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    295\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    296\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    298\u001b[0m )\n\u001b[0;32m    299\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:237\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    236\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m--> 237\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:135\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[1;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[0;32m    133\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m    134\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m--> 135\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m    136\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[1;32mc:\\Users\\Crescent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:110\u001b[0m, in \u001b[0;36mrotate_half\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    108\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    109\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :]\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import contextlib, math, random, numpy as np, torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "scaler = torch.amp.GradScaler(enabled=use_cuda)\n",
    "\n",
    "patience, since_best = 2, 0\n",
    "best_score = (-1.0, float(\"inf\"))  # (acc, -ece) target is max\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    reward_model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"epoch {epoch}\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "\n",
    "        # autocast only on CUDA\n",
    "        ctx = (torch.amp.autocast(device_type='cuda', enabled=True) if use_cuda\n",
    "               else contextlib.nullcontext())  # disable on CPU\n",
    "        with ctx:\n",
    "            loss, _ = step_batch(reward_model, batch) # returns (loss, delta_cpu)\n",
    "        \n",
    "        # backprop with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optim)\n",
    "        torch.nn.utils.clip_grad_norm_(reward_model.parameters(), GRAD_CLIP)\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        global_step += 1\n",
    "        log_train_step(global_step, loss.item(), epoch)\n",
    "\n",
    "    # validation (also collect deltas for histogram)\n",
    "    reward_model.eval()\n",
    "    all_deltas = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            _, delta = step_batch(reward_model, batch)   # delta already detached\n",
    "            all_deltas.extend(delta.cpu().numpy().tolist())\n",
    "\n",
    "    val_metrics = evaluate(reward_model, val_loader, bins=10)  # or evaluate_riskwise(...)\n",
    "    save_metrics(val_metrics, f\"reward_eval_val_epoch{epoch:02d}.json\")\n",
    "    log_val_epoch(epoch, val_metrics)\n",
    "    dump_val_deltas(epoch, all_deltas)\n",
    "    print(\"val:\", val_metrics)\n",
    "\n",
    "    # select best by (acc ↑, ECE ↓)\n",
    "    score = (val_metrics[\"pairwise_accuracy\"], -val_metrics[\"ece\"])\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        save_ckpt(reward_model, sub=\"best\")\n",
    "        since_best = 0\n",
    "    else:\n",
    "        since_best += 1\n",
    "        if since_best >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    save_ckpt(reward_model, sub=f\"epoch{epoch:02d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d4237",
   "metadata": {},
   "source": [
    "## plot training vs val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# load step losses\n",
    "steps, losses = [], []\n",
    "with open(METRIC_DIR / \"train_steps.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        steps.append(rec[\"step\"]); losses.append(rec[\"loss\"])\n",
    "\n",
    "# smooth a bit for readability (moving avg window=50)\n",
    "def moving_avg(x, w=50):\n",
    "    if len(x) < w: return np.array(x, dtype=float)\n",
    "    c = np.cumsum(np.insert(x, 0, 0.0))\n",
    "    return (c[w:] - c[:-w]) / float(w)\n",
    "\n",
    "sm = moving_avg(losses, w=50)\n",
    "xs = np.arange(len(sm))  # pseudo-steps for smoothed series\n",
    "\n",
    "# get per-epoch val loss proxy from ECE or 1-acc? plot accuracy separately.\n",
    "# If want val loss, can compute it in evaluate() and log it; for now we do train loss only.\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(xs, sm)\n",
    "plt.title(\"Training loss (moving avg)\")\n",
    "plt.xlabel(\"Step (smoothed index)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8b5fa",
   "metadata": {},
   "source": [
    "## plot validation Pairwaise Accuracy & ECE vs epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, matplotlib.pyplot as plt\n",
    "\n",
    "epochs, accs, eces = [], [], []\n",
    "with open(METRIC_DIR / \"val_epochs.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        epochs.append(rec[\"epoch\"])\n",
    "        accs.append(rec[\"pairwise_accuracy\"])\n",
    "        eces.append(rec[\"ece\"])\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, accs, marker=\"o\")\n",
    "plt.title(\"Validation Pairwise Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(epochs)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, eces, marker=\"o\")\n",
    "plt.title(\"Validation Calibration (ECE, 10 bins)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ECE\")\n",
    "plt.xticks(epochs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445de12e",
   "metadata": {},
   "source": [
    "## Bar chart: validation accuracy by risk bucket (per latest epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ff2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, matplotlib.pyplot as plt\n",
    "\n",
    "# read the latest epoch record\n",
    "last = None\n",
    "with open(METRIC_DIR / \"val_epochs.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        last = json.loads(line)\n",
    "\n",
    "acc_by_risk = last.get(\"acc_by_risk\", {})\n",
    "labels = list(acc_by_risk.keys())\n",
    "vals = [acc_by_risk[k] for k in labels]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels, vals)\n",
    "plt.title(f\"Accuracy by risk (epoch {last['epoch']})\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4cffde",
   "metadata": {},
   "source": [
    "## histogram of validation margins Δ = r⁺−r⁻ (latest epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, matplotlib.pyplot as plt\n",
    "\n",
    "delta_files = sorted(glob.glob(str(VAL_DELTAS_DIR / \"deltas_epoch*.json\")))\n",
    "with open(delta_files[-1], \"r\", encoding=\"utf-8\") as f:\n",
    "    rec = json.loads(f.read())\n",
    "deltas = rec[\"deltas\"]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(deltas, bins=50)\n",
    "plt.title(f\"Validation Δ = r_pos - r_neg (epoch {rec['epoch']})\")\n",
    "plt.xlabel(\"Δ margin\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
