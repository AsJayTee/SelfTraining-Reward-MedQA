{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe70a7a",
   "metadata": {},
   "source": [
    "# **Reward Model Trainer**\n",
    "\n",
    "This notebook implements an end-to-end training pipeline for a Reward Model used in preference-based fine-tuning and reinforcement learning for language models.\n",
    "\n",
    "It covers data preparation, tokenisation, model setup, training loop and evaluation metrics.\n",
    "\n",
    "**Author:** Crescent - DSA4213 Group 18\n",
    "\n",
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "1. [Environment Setup](#env-setup)\n",
    "2. [Imports](#imports)\n",
    "3. [Configuration](#config)\n",
    "4. [Utilities](#utils)\n",
    "5. [Training & Evaluation](#train-eval)\n",
    "6. [Visualisations](#viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f26b7",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "\n",
    "**Main objectives:**\n",
    "1. Load and preprocess preference-pair datasets.\n",
    "2. Tokenise and batch inputs using the Hugging Face `transformers` library.\n",
    "3. Initialise and fine-tune a `Llama 3.2`-based reward model.\n",
    "4. Compute and log training loss, validation metrics, and save model checkpoints.\n",
    "5. Visualise loss trends and model confidence distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513d382",
   "metadata": {},
   "source": [
    "# 1. Environment Setup <a id='env-setup'></a>\n",
    "\n",
    "Installs dependencies automatically depending on where it's run:\n",
    "- On VS Code (Windows/CPU): CPU-only build of PyTorch\n",
    "- On RONIN (Linux/GPU): CUDA 12.1 build of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f4060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Detected Windows environment. Installing CPU build...\n",
      "Installing common dependencies: transformers, tqdm, matplotlib, numpy, torchinfo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pip', 'install', 'transformers', 'tqdm', 'matplotlib', 'numpy', 'torchinfo'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "\n",
    "system_name = platform.system().lower()\n",
    "is_ronin = \"ronin\" in platform.node().lower()\n",
    "\n",
    "if system_name == \"windows\":\n",
    "    print(\"üñ•Ô∏è Detected Windows environment. Installing CPU build...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"torch\"], check=False)\n",
    "elif is_ronin or system_name == \"linux\":\n",
    "    print(\"üöÄ Detected Linux/RONIN GPU environment. Installing CUDA 12.1 build...\")\n",
    "    subprocess.run([\n",
    "        \"pip\", \"install\", \"torch\",\n",
    "        \"--index-url\", \"https://download.pytorch.org/whl/cu121\"\n",
    "    ], check=False)\n",
    "else:\n",
    "    print(\"‚öôÔ∏è Unknown environment ‚Äî installing CPU build by default.\")\n",
    "    subprocess.run([\"pip\", \"install\", \"torch\"], check=False)\n",
    "\n",
    "common_packages = [\n",
    "    \"transformers\",\n",
    "    \"tqdm\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"torchinfo\"\n",
    "]\n",
    "\n",
    "print(f\"Installing common dependencies: {', '.join(common_packages)}\")\n",
    "subprocess.run([\"pip\", \"install\", *common_packages], check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701cdde",
   "metadata": {},
   "source": [
    "# 2. Imports <a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10b4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "import contextlib, glob, json, math, random, time, numpy as np, matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ec635",
   "metadata": {},
   "source": [
    "# 3. Configuration <a id='config'></a>\n",
    "Set constants, hyperparameters, and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e3b8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Model & Directories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Current and source directories\n",
    "CUR_DIR = Path.cwd()\n",
    "SRC_DIR = CUR_DIR.parent\n",
    "\n",
    "# Data directories and files\n",
    "DATA_DIR = SRC_DIR / \"data\" / \"processed\"\n",
    "PAIRS_PATH = DATA_DIR / \"preference_pairs.json\"\n",
    "#TEST_QNA_PATH = DATA_DIR / \"test_qna_with_confidence.json\"\n",
    "TRAIN_PATH = DATA_DIR / \"preference_pairs_train.json\"\n",
    "VAL_PATH   = DATA_DIR / \"preference_pairs_val.json\"\n",
    "\n",
    "# Checkpoint and metric directories\n",
    "CKPT_DIR   = CUR_DIR / \"checkpoints\"\n",
    "METRIC_DIR = CUR_DIR / \"metrics\"\n",
    "TRAIN_LOG = METRIC_DIR / \"train_steps.jsonl\"         # per-step loss\n",
    "VAL_EPOCH_LOG = METRIC_DIR / \"val_epochs.jsonl\"      # per-epoch metrics\n",
    "VAL_DELTAS_DIR = METRIC_DIR / \"val_deltas\"           # per-epoch margins for histogram\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in (DATA_DIR, CKPT_DIR, METRIC_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Training Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
    "# Data split ratios\n",
    "TRAIN_RATIO = 0.9\n",
    "VAL_RATIO   = 0.1\n",
    "TEST_RATIO  = 0.0\n",
    "\n",
    "# Flags for data processing\n",
    "DROP_WEAK = False   # Drop low-confidence preference pairs (set True for cleaner supervision)\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LEN    = 1024    # Maximum tokenised sequence length\n",
    "BETA       = 3.0     # Scales confidence penalty into a sample weight\n",
    "BATCH_SIZE = 2       # Training batch size\n",
    "EPOCHS     = 5\n",
    "GRAD_CLIP  = 1.0\n",
    "LR         = 2e-5\n",
    "WEIGHT_DECAY = 0.0\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d160a",
   "metadata": {},
   "source": [
    "# 4. Utilities <a id='utils'></a>\n",
    "Helper functions for tokenisation, loss computation, logging, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27d6d3",
   "metadata": {},
   "source": [
    "## JSON I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2264741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_json(p: Path):\n",
    "    return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _write_json(obj, p: Path):\n",
    "    p.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    print(f\"[saved] {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b4ef0",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3eed9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_preference_pairs(\n",
    "    pairs_path: Path,\n",
    "    out_dir: Path,\n",
    "    train_ratio: float = 0.9,\n",
    "    val_ratio: float = 0.1,\n",
    "    test_ratio: float = 0.0,\n",
    "    seed: int = 42,\n",
    "    drop_weak: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Split preference_pairs.json into train/val(/test) without question leakage.\n",
    "\n",
    "    Args:\n",
    "        pairs_path: path to preference_pairs.json\n",
    "        out_dir: directory to write split files\n",
    "        train_ratio, val_ratio, test_ratio: must sum to 1.0 (test optional)\n",
    "        seed: RNG seed for reproducibility\n",
    "        drop_weak: if True, drops pairs with score_difference==0 and pairs where both ratings == 1\n",
    "\n",
    "    Writes:\n",
    "        preference_pairs.train.json\n",
    "        preference_pairs.val.json\n",
    "        (optional) preference_pairs.test.json\n",
    "        preference_pairs_split_stats.json\n",
    "\n",
    "    Returns:\n",
    "        stats dict with counts, distributions, and dropped info.\n",
    "    \"\"\"\n",
    "    assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _rating_score(ans: Dict[str, Any]) -> int:\n",
    "        # Prefer explicit numeric 'score'; fallback parse from 'rating' like \"3-Incomplete\"\n",
    "        if \"score\" in ans and ans[\"score\"] is not None:\n",
    "            return int(ans[\"score\"])\n",
    "        r = ans.get(\"rating\", \"\")\n",
    "        return int(r[0]) if isinstance(r, str) and r[:1].isdigit() else -1  # -1 if unknown\n",
    "\n",
    "    # Load data\n",
    "    pairs = _read_json(pairs_path)\n",
    "\n",
    "    # Optional filtering\n",
    "    dropped = {\"score_diff_zero\": 0, \"both_score1\": 0} # counts how many pairs were removed for each reason\n",
    "    clean = []\n",
    "    if drop_weak:\n",
    "        for ex in pairs:\n",
    "            if ex.get(\"score_difference\", None) == 0:\n",
    "                dropped[\"score_diff_zero\"] += 1\n",
    "                continue\n",
    "            sp = _rating_score(ex.get(\"preferred_answer\", {}))\n",
    "            sr = _rating_score(ex.get(\"rejected_answer\", {}))\n",
    "            if sp == 1 and sr == 1:\n",
    "                dropped[\"both_score1\"] += 1\n",
    "                continue\n",
    "            clean.append(ex) # only store if passes filters\n",
    "    else:\n",
    "        clean = pairs\n",
    "\n",
    "    # Group by question_id (no leakage across splits)\n",
    "    by_qid = defaultdict(list)\n",
    "    for ex in clean:\n",
    "        qid = ex[\"question_id\"]\n",
    "        by_qid[qid].append(ex)\n",
    "\n",
    "    qids = list(by_qid.keys())\n",
    "    random.seed(seed)\n",
    "    random.shuffle(qids)\n",
    "\n",
    "    # Stratify by risk level (keeps similar risk mix across splits)\n",
    "    def majority_risk(items):\n",
    "        return Counter(e.get(\"risk_level\", \"UNKNOWN\") for e in items).most_common(1)[0][0]\n",
    "\n",
    "    risk_to_qids = defaultdict(list)\n",
    "    for qid in qids:\n",
    "        risk_to_qids[majority_risk(by_qid[qid])].append(qid)\n",
    "\n",
    "    train_qids, val_qids, test_qids = set(), set(), set()\n",
    "    for _, bucket in risk_to_qids.items():\n",
    "        random.shuffle(bucket)\n",
    "        n = len(bucket)\n",
    "        n_train = int(round(n * train_ratio))\n",
    "        n_val   = int(round(n * val_ratio))\n",
    "        # ensure total fits by assigning remainder to test\n",
    "        n_test  = n - n_train - n_val\n",
    "        train_qids.update(bucket[:n_train])\n",
    "        val_qids.update(bucket[n_train:n_train+n_val])\n",
    "        test_qids.update(bucket[n_train+n_val:])\n",
    "\n",
    "    # Materialise splits\n",
    "    train_pairs = [e for q in train_qids for e in by_qid[q]]\n",
    "    val_pairs   = [e for q in val_qids   for e in by_qid[q]]\n",
    "    test_pairs  = [e for q in test_qids  for e in by_qid[q]] if test_ratio > 0 else []\n",
    "\n",
    "    # Save\n",
    "    _write_json(train_pairs, out_dir / \"preference_pairs_train.json\")\n",
    "    _write_json(val_pairs,   out_dir / \"preference_pairs_val.json\")\n",
    "    if test_ratio > 0:\n",
    "        _write_json(test_pairs, out_dir / \"preference_pairs_test.json\")\n",
    "\n",
    "    def _dist(lst):\n",
    "        return dict(Counter(e.get(\"risk_level\", \"UNKNOWN\") for e in lst))\n",
    "\n",
    "    stats = {\n",
    "        \"seed\": seed,\n",
    "        \"drop_weak\": drop_weak,\n",
    "        \"dropped\": dropped,\n",
    "        \"counts\": {\n",
    "            \"train\": len(train_pairs),\n",
    "            \"val\":   len(val_pairs),\n",
    "            \"test\":  len(test_pairs),\n",
    "        },\n",
    "        \"unique_qids\": {\n",
    "            \"train\": len(train_qids),\n",
    "            \"val\":   len(val_qids),\n",
    "            \"test\":  len(test_qids),\n",
    "        },\n",
    "        \"risk_dist\": {\n",
    "            \"train\": _dist(train_pairs),\n",
    "            \"val\":   _dist(val_pairs),\n",
    "            \"test\":  _dist(test_pairs),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    _write_json(stats, out_dir / \"preference_pairs_split_stats.json\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6da042",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = split_preference_pairs(\n",
    "    pairs_path = PAIRS_PATH,\n",
    "    out_dir    = DATA_DIR,\n",
    "    train_ratio= TRAIN_RATIO, # 90/10 train/val\n",
    "    val_ratio  = VAL_RATIO,\n",
    "    test_ratio = TEST_RATIO, # set to 0.1 if want a test split\n",
    "    seed       = SEED,\n",
    "    drop_weak  = DROP_WEAK # change to True if want cleaner pairs\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3ddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27775, 3327)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load splits\n",
    "train_pairs = _read_json(TRAIN_PATH)\n",
    "val_pairs = _read_json(VAL_PATH)\n",
    "len(train_pairs), len(val_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d181926",
   "metadata": {},
   "source": [
    "## Dataset + Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f49faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer (ensure PAD exists)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a2ac96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13888, 1664)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_input(q, a):\n",
    "    return f\"Question:\\n{q}\\n\\nAnswer:\\n{a}\"\n",
    "\n",
    "# Dataset and collate\n",
    "class PrefPairDataset(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        ex = self.items[i]\n",
    "        x_pos = build_input(ex[\"question_text\"], ex[\"preferred_answer\"][\"answer_text\"])\n",
    "        x_neg = build_input(ex[\"question_text\"], ex[\"rejected_answer\"][\"answer_text\"])\n",
    "        pos = tokenizer(x_pos, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        neg = tokenizer(x_neg, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        w = 1.0 + BETA * float(ex.get(\"confidence_penalty\", 0.0))\n",
    "        risk = ex.get(\"risk_level\", \"UNKNOWN\")\n",
    "        return {\"pos\": pos, \"neg\": neg, \"weight\": torch.tensor(w, dtype=torch.float), \"risk\": risk}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    def stack(side):\n",
    "        ids  = [b[side][\"input_ids\"].squeeze(0) for b in batch]\n",
    "        attn = [b[side][\"attention_mask\"].squeeze(0) for b in batch]\n",
    "        ids  = torch.nn.utils.rnn.pad_sequence(ids,  batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        attn = torch.nn.utils.rnn.pad_sequence(attn, batch_first=True, padding_value=0)\n",
    "        return {\"input_ids\": ids, \"attention_mask\": attn}\n",
    "    weights = torch.stack([b[\"weight\"] for b in batch])\n",
    "    risks   = [b[\"risk\"]   for b in batch]\n",
    "    return {\"pos\": stack(\"pos\"), \"neg\": stack(\"neg\"), \"weight\": weights, \"risk\": risks}\n",
    "\n",
    "# build loaders\n",
    "train_loader = DataLoader(PrefPairDataset(train_pairs), batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(PrefPairDataset(val_pairs),   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088496b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:18<00:00,  9.30s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: CPU\n",
      "Loaded: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Use 'dtype' instead of deprecated 'torch_dtype'\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "device_map = \"auto\" if torch.cuda.is_available() else None\n",
    "max_memory = {0: \"13GB\"} if torch.cuda.is_available() else None\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device_map,\n",
    "    low_cpu_mem_usage=True,\n",
    "    max_memory=max_memory\n",
    ")\n",
    "\n",
    "reward_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "reward_model = reward_model.float()  # Ensure model is in FP32\n",
    "\n",
    "# align special tokens / training toggles\n",
    "# reward_model.config.eos_token_id = tokenizer.eos_token_id\n",
    "# reward_model.config.bos_token_id = getattr(tokenizer, \"bos_token_id\", tokenizer.eos_token_id)\n",
    "# reward_model.config.use_cache = False  # safer during training\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reward_model = reward_model.to(device)\n",
    "\n",
    "print(\"Device:\", device)\n",
    "print(\"Loaded:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27bd1b",
   "metadata": {},
   "source": [
    "## Check model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d93aa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type (var_name))                                           Input Shape               Output Shape              Param #                   Trainable\n",
       "=====================================================================================================================================================================\n",
       "LlamaForSequenceClassification (LlamaForSequenceClassification)   --                        --                        --                        True\n",
       "‚îú‚îÄLlamaModel (model)                                              [1, 1024]                 --                        --                        True\n",
       "‚îÇ    ‚îî‚îÄEmbedding (embed_tokens)                                   [1, 1024]                 [1, 1024, 3072]           394,002,432               True\n",
       "‚îÇ    ‚îî‚îÄLlamaRotaryEmbedding (rotary_emb)                          [1, 1024, 3072]           [1, 1024, 128]            --                        --\n",
       "‚îÇ    ‚îî‚îÄModuleList (layers)                                        --                        --                        --                        True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (0)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (1)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (2)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (3)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (4)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (5)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (6)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (7)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (8)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (9)                                 [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (10)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (11)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (12)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (13)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (14)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (15)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (16)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (17)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (18)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (19)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (20)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (21)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (22)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (23)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (24)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (25)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (26)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLlamaDecoderLayer (27)                                [1, 1024, 3072]           [1, 1024, 3072]           100,669,440               True\n",
       "‚îÇ    ‚îî‚îÄLlamaRMSNorm (norm)                                        [1, 1024, 3072]           [1, 1024, 3072]           3,072                     True\n",
       "‚îú‚îÄLinear (score)                                                  [1, 1024, 3072]           [1, 1024, 1]              3,072                     True\n",
       "=====================================================================================================================================================================\n",
       "Total params: 3,212,752,896\n",
       "Trainable params: 3,212,752,896\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.21\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 7801.41\n",
       "Params size (MB): 12851.01\n",
       "Estimated Total Size (MB): 20652.44\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy input with same dimensions as expected by model\n",
    "batch_size = 1\n",
    "seq_len = MAX_LEN\n",
    "\n",
    "# Build synthetic data\n",
    "dummy_input_ids = torch.randint(\n",
    "    low=0,\n",
    "    high=tokenizer.vocab_size,\n",
    "    size=(batch_size, seq_len),\n",
    "    dtype=torch.long\n",
    ")\n",
    "dummy_attention_mask = torch.ones((batch_size, seq_len), dtype=torch.long)\n",
    "\n",
    "# Run summary (depth controls how detailed the nested layer view is)\n",
    "summary(\n",
    "    reward_model,\n",
    "    input_data={\n",
    "        \"input_ids\": dummy_input_ids,\n",
    "        \"attention_mask\": dummy_attention_mask\n",
    "    },\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    depth=3, # adjust depth for more/less detail\n",
    "    row_settings=(\"var_names\",),  # shows variable names per layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f27f47da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer (path)                                                 Type                   Output Shape                      Param #  Trainable\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "model.embed_tokens                                           Embedding              (1, 64, 3072)                 394,002,432 394,002,432\n",
      "model.rotary_emb                                             LlamaRotaryEmbedding   [(1, 64, 128), (1, 64, 128)]            0          0\n",
      "model.layers.0.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.0.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.0.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.0.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.0.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.0.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.0.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.0.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.0.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.0.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.1.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.1.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.1.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.1.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.1.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.1.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.1.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.1.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.1.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.1.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.2.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.2.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.2.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.2.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.2.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.2.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.2.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.2.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.2.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.2.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.3.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.3.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.3.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.3.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.3.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.3.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.3.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.3.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.3.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.3.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.4.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.4.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.4.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.4.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.4.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.4.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.4.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.4.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.4.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.4.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.5.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.5.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.5.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.5.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.5.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.5.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.5.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.5.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.5.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.5.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.6.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.6.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.6.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.6.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.6.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.6.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.6.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.6.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.6.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.6.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.7.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.7.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.7.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.7.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.7.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.7.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.7.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.7.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.7.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.7.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.8.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.8.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.8.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.8.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.8.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.8.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.8.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.8.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.8.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.8.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.9.input_layernorm                               LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.9.self_attn.q_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.9.self_attn.k_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.9.self_attn.v_proj                              Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.9.self_attn.o_proj                              Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.9.post_attention_layernorm                      LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.9.mlp.gate_proj                                 Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.9.mlp.act_fn                                    SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.9.mlp.up_proj                                   Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.9.mlp.down_proj                                 Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.10.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.10.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.10.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.10.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.10.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.10.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.10.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.10.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.10.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.10.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.11.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.11.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.11.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.11.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.11.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.11.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.11.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.11.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.11.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.11.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.12.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.12.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.12.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.12.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.12.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.12.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.12.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.12.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.12.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.12.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.13.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.13.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.13.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.13.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.13.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.13.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.13.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.13.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.13.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.13.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.14.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.14.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.14.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.14.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.14.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.14.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.14.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.14.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.14.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.14.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.15.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.15.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.15.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.15.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.15.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.15.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.15.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.15.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.15.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.15.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.16.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.16.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.16.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.16.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.16.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.16.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.16.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.16.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.16.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.16.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.17.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.17.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.17.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.17.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.17.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.17.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.17.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.17.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.17.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.17.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.18.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.18.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.18.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.18.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.18.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.18.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.18.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.18.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.18.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.18.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.19.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.19.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.19.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.19.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.19.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.19.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.19.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.19.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.19.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.19.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.20.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.20.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.20.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.20.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.20.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.20.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.20.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.20.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.20.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.20.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.21.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.21.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.21.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.21.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.21.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.21.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.21.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.21.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.21.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.21.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.22.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.22.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.22.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.22.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.22.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.22.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.22.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.22.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.22.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.22.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.23.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.23.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.23.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.23.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.23.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.23.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.23.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.23.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.23.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.23.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.24.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.24.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.24.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.24.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.24.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.24.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.24.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.24.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.24.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.24.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.25.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.25.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.25.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.25.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.25.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.25.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.25.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.25.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.25.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.25.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.26.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.26.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.26.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.26.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.26.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.26.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.26.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.26.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.26.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.26.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.layers.27.input_layernorm                              LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.27.self_attn.q_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.27.self_attn.k_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.27.self_attn.v_proj                             Linear                 (1, 64, 1024)                   3,145,728  3,145,728\n",
      "model.layers.27.self_attn.o_proj                             Linear                 (1, 64, 3072)                   9,437,184  9,437,184\n",
      "model.layers.27.post_attention_layernorm                     LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "model.layers.27.mlp.gate_proj                                Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.27.mlp.act_fn                                   SiLU                   (1, 64, 8192)                           0          0\n",
      "model.layers.27.mlp.up_proj                                  Linear                 (1, 64, 8192)                  25,165,824 25,165,824\n",
      "model.layers.27.mlp.down_proj                                Linear                 (1, 64, 3072)                  25,165,824 25,165,824\n",
      "model.norm                                                   LlamaRMSNorm           (1, 64, 3072)                       3,072      3,072\n",
      "score                                                        Linear                 (1, 64, 1)                          3,072      3,072\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total params:     3,212,752,896  (~12255.7 MB at float32)\n",
      "Trainable params: 3,212,752,896  (~12255.7 MB)\n",
      "Frozen params:    0  (~0.0 MB)\n",
      "Seq len used for summary: 64, batch size: 1\n"
     ]
    }
   ],
   "source": [
    "def _num_params(module):\n",
    "    total = sum(p.numel() for p in module.parameters(recurse=False))\n",
    "    train = sum(p.numel() for p in module.parameters(recurse=False) if p.requires_grad)\n",
    "    return total, train\n",
    "\n",
    "def _shape_str(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return tuple(x.shape)\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        # show first few shapes if it's a tuple/list\n",
    "        parts = []\n",
    "        for i, it in enumerate(x[:3]):\n",
    "            if isinstance(it, torch.Tensor):\n",
    "                parts.append(str(tuple(it.shape)))\n",
    "            else:\n",
    "                parts.append(type(it).__name__)\n",
    "        if len(x) > 3:\n",
    "            parts.append(\"...\")\n",
    "        return \"[\" + \", \".join(parts) + \"]\"\n",
    "    return type(x).__name__\n",
    "\n",
    "def model_summary(model, tokenizer, seq_len=64, verbose=True):\n",
    "    \"\"\"\n",
    "    Prints a table:\n",
    "      Layer (path) | Type | Output Shape | Param # (trainable)\n",
    "    Uses a dummy forward pass with batch_size=1 and input length = seq_len.\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    dtype  = next(model.parameters()).dtype\n",
    "    bytes_per = 2 if dtype in (torch.float16, torch.bfloat16) else 4\n",
    "\n",
    "    # 1) Prepare a tiny dummy batch\n",
    "    with torch.no_grad():\n",
    "        toks = tokenizer(\"dummy\", return_tensors=\"pt\", add_special_tokens=True)\n",
    "        # expand to desired seq_len (pad tokens)\n",
    "        input_ids = torch.full((1, seq_len), fill_value=tokenizer.pad_token_id, dtype=torch.long)\n",
    "        attn_mask = torch.zeros((1, seq_len), dtype=torch.long)\n",
    "        # put some non-pad tokens at the start\n",
    "        L = min(toks[\"input_ids\"].shape[1], seq_len)\n",
    "        input_ids[:, :L] = toks[\"input_ids\"][:, :L]\n",
    "        attn_mask[:, :L] = 1\n",
    "        batch = {\"input_ids\": input_ids.to(device), \"attention_mask\": attn_mask.to(device)}\n",
    "\n",
    "    # 2) Collect module info (param counts) and register forward hooks for output shapes\n",
    "    names = {m: n for n, m in model.named_modules()}  # module -> qualified name\n",
    "    layer_infos = OrderedDict() # preserve execution order\n",
    "    handles = []\n",
    "\n",
    "    def hook(module, inputs, outputs):\n",
    "        name = names.get(module, module.__class__.__name__)\n",
    "        if name == \"\": name = module.__class__.__name__\n",
    "        if name not in layer_infos:\n",
    "            p_total, p_train = _num_params(module)\n",
    "            layer_infos[name] = {\n",
    "                \"type\": module.__class__.__name__,\n",
    "                \"params\": p_total,\n",
    "                \"trainable\": p_train,\n",
    "                \"out\": _shape_str(outputs),\n",
    "            }\n",
    "\n",
    "    # only hook leaf modules to avoid noisy duplicates\n",
    "    for m in model.modules():\n",
    "        is_leaf = len(list(m.children())) == 0\n",
    "        if is_leaf:\n",
    "            try:\n",
    "                handles.append(m.register_forward_hook(hook))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 3) Forward pass (to populate shapes)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**batch)\n",
    "\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "\n",
    "    # 4) Print table\n",
    "    total_params = sum(v[\"params\"] for v in layer_infos.values())\n",
    "    train_params = sum(v[\"trainable\"] for v in layer_infos.values())\n",
    "    frozen_params = total_params - train_params\n",
    "    total_mb   = (total_params * bytes_per) / (1024**2)\n",
    "    train_mb   = (train_params * bytes_per) / (1024**2)\n",
    "    frozen_mb  = (frozen_params * bytes_per) / (1024**2)\n",
    "\n",
    "    header = f\"{'Layer (path)':60} {'Type':22} {'Output Shape':28} {'Param #':>12} {'Trainable':>10}\"\n",
    "    line   = \"-\" * len(header)\n",
    "    if verbose:\n",
    "        print(header)\n",
    "        print(line)\n",
    "        for name, info in layer_infos.items():\n",
    "            print(f\"{name:60} {info['type']:22} {str(info['out'])[:28]:28} {info['params']:12,} {info['trainable']:10,}\")\n",
    "        print(line)\n",
    "        print(f\"Total params:     {total_params:,}  (~{total_mb:.1f} MB at {str(dtype).replace('torch.','')})\")\n",
    "        print(f\"Trainable params: {train_params:,}  (~{train_mb:.1f} MB)\")\n",
    "        print(f\"Frozen params:    {frozen_params:,}  (~{frozen_mb:.1f} MB)\")\n",
    "        print(f\"Seq len used for summary: {seq_len}, batch size: 1\")\n",
    "\n",
    "    # 5) Return a dict if you want to use programmatically\n",
    "    return {\n",
    "        \"layers\": layer_infos,\n",
    "        \"totals\": {\n",
    "            \"total_params\": total_params,\n",
    "            \"trainable_params\": train_params,\n",
    "            \"frozen_params\": frozen_params,\n",
    "            \"dtype\": str(dtype),\n",
    "            \"mb_total\": total_mb,\n",
    "            \"mb_trainable\": train_mb,\n",
    "            \"mb_frozen\": frozen_mb,\n",
    "            \"bytes_per_param\": bytes_per,\n",
    "            \"seq_len\": seq_len,\n",
    "        }\n",
    "    }\n",
    "\n",
    "# run it\n",
    "_ = model_summary(reward_model, tokenizer, seq_len=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0259ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== freeze/unfreeze helpers =====\n",
    "# Example: freeze all base layers, train only the classification head\n",
    "def freeze_all_but_head(m):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False\n",
    "    # common head names: 'score' (HF seq-classification), else 'classifier'\n",
    "    head = getattr(m, \"score\", None) or getattr(m, \"classifier\", None)\n",
    "    if head is not None:\n",
    "        for p in head.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "# Example usage:\n",
    "# freeze_all_but_head(reward_model)\n",
    "# print(\"After freezing:\")\n",
    "# total, trainable, frozen = count_params(reward_model)\n",
    "# print(f\"Trainable params:  {trainable:,}  (~{human_mb(trainable):.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e415b8c",
   "metadata": {},
   "source": [
    "## Training step (pairwise Bradley-Terry loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5989d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_batch(model, batch):\n",
    "    \"\"\"\n",
    "    Perform one training step using the pairwise Bradley-Terry (logistic) loss.\n",
    "    \n",
    "    Commonly used in Reward Model training for RLHF or preference learning, \n",
    "    where the model learns to assign higher scalar reqards to preferred samples \n",
    "    (positive responses) than to non-preferred ones (negative responses).\n",
    "    \n",
    "    Intuition:\n",
    "    - For each (positive, negative) pair, compute the model scores:\n",
    "        r_pos = model(preferred response)\n",
    "        r_neg = model(non-preferred response)\n",
    "    - The model should learn r_pos > r_neg.\n",
    "    - The probability that the model ranks the positive higher is:\n",
    "        P(pos > neg) = œÉ(r_pos - r_neg), where œÉ(x) is the sigmoid function.\n",
    "    - The loss encourages this probability to be close to 1.\n",
    "\n",
    "    Args:\n",
    "        model: the reward model (a HF seq-classification model outputting scalar logits)\n",
    "        batch: a dict with keys:\n",
    "            - \"pos\": tokenized batch of preferred responses\n",
    "            - \"neg\": tokenized batch of non-preferred responses\n",
    "            - \"weight\": tensor of shape (B,) with sample weights (e.g., from confidence penalties)\n",
    "    \n",
    "    Returns:\n",
    "        loss: the computed loss (a scalar tensor)\n",
    "        delta: tensor of shape (B,) with r_pos - r_neg for each pair (detached from graph)\n",
    "    \"\"\"\n",
    "\n",
    "    # Move all inputs to model device\n",
    "    for side in (\"pos\",\"neg\"):\n",
    "        for k in batch[side]:\n",
    "            batch[side][k] = batch[side][k].to(model.device)\n",
    "    w = batch[\"weight\"].to(model.device)\n",
    "\n",
    "    # Forward pass: compute scalar rewards for positive and negative samples\n",
    "    r_pos = model(**batch[\"pos\"]).logits.squeeze(-1) # shape: (B,)\n",
    "    r_neg = model(**batch[\"neg\"]).logits.squeeze(-1) # shape: (B,)\n",
    "\n",
    "    # Pairwise Bradley-Terry (logistic) loss\n",
    "    delta = r_pos - r_neg\n",
    "    loss_core = -torch.log(torch.sigmoid(delta) + 1e-8)\n",
    "    loss = (w * loss_core).mean()\n",
    "    return loss, delta.detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148c6f2",
   "metadata": {},
   "source": [
    "## Validation (pairwise accuracy + ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_riskwise(model, loader, bins=10):\n",
    "    \"\"\"\n",
    "    Evaluate pairwise accuracy and calibration (ECE), and accuracy broken down by risk level.\n",
    "\n",
    "    Pairwise setting:\n",
    "    - The model outputs scalar rewards r(x). For each preference pair (pos, neg),\n",
    "      compute delta = r_pos - r_neg and the probability p = œÉ(delta) that the positive\n",
    "      item is preferred.\n",
    "    \n",
    "    Metrics:\n",
    "    \n",
    "    - Pairwise accuracy:\n",
    "        acc = (1/N) * Œ£ 1{delta_i > 0}\n",
    "        i.e., the fraction of pairs where r_pos > r_neg.\n",
    "    \n",
    "    - Expected Calibration Error (ECE):\n",
    "        ECE = Œ£_b (n_b / N) * | acc_b - conf_b |\n",
    "      where for bin b:\n",
    "        - n_b = number of samples in bin b\n",
    "        - acc_b = average correctness in bin b\n",
    "        - conf_b = average model confidence (p) in bin b\n",
    "      Bins partition [0, 1] into `bins` equal-width intervals.\n",
    "      Empty bins are skipped.\n",
    "    \n",
    "    - Accuracy by risk level (`acc_by_risk`):\n",
    "        Dictionary mapping each risk bucket/value to its mean pairwise accuracy.\n",
    "\n",
    "    Args:\n",
    "        model: the reward model\n",
    "        loader: DataLoader providing batches of preference pairs\n",
    "        bins: number of bins for ECE calculation\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            \"pairwise_accuracy\": float,\n",
    "            \"ece\": float,\n",
    "            \"acc_by_risk\": Dict[Any, float],\n",
    "            \"ece_detail\": {\n",
    "                \"bin_edges\": np.ndarray,  # shape (bins+1,)\n",
    "                \"bin_counts\": np.ndarray, # shape (bins,)\n",
    "                \"bin_acc\": np.ndarray,    # shape (bins,)\n",
    "                \"bin_conf\": np.ndarray,   # shape (bins,)\n",
    "            },\n",
    "            \"deltas\": np.ndarray,   # shape (N,), r_pos - r_neg for each pair\n",
    "            \"probs\": np.ndarray,    # shape (N,), œÉ(delta)\n",
    "            \"corrects\": np.ndarray, # shape (N,), 1 if delta>0 else 0\n",
    "        }\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    deltas_list = []\n",
    "    probs_list = []\n",
    "    corrects_list = []\n",
    "    risks_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            #  move inputs to model device\n",
    "            for side in (\"pos\",\"neg\"):\n",
    "                for k in batch[side]:\n",
    "                    batch[side][k] = batch[side][k].to(model.device)\n",
    "            \n",
    "            # Forward pass: compute scalar rewards for positive and negative samples\n",
    "            r_pos = model(**batch[\"pos\"]).logits.squeeze(-1) # shape: (B,)\n",
    "            r_neg = model(**batch[\"neg\"]).logits.squeeze(-1) # shape: (B,)\n",
    "            \n",
    "            # Pairwise probabilities and correctness labels\n",
    "            delta = r_pos - r_neg\n",
    "            p = torch.sigmoid(delta).cpu().numpy() # shape: (B,)\n",
    "            c = (delta.cpu().numpy() > 0).astype(np.float32) # shape: (B,)\n",
    "\n",
    "            deltas_list.append(delta.detach().cpu().numpy())\n",
    "            probs_list.append(p)\n",
    "            corrects_list.append(c)\n",
    "\n",
    "            # Risks from collate_fn\n",
    "            if \"risk\" in batch:\n",
    "                risk_obj = batch[\"risk\"]\n",
    "                if isinstance(risk_obj, torch.Tensor):\n",
    "                    risks_all.extend(risk_obj.detach().cpu().numpy().tolist())\n",
    "                else:\n",
    "                    risks_all.extend(list(risk_obj))\n",
    "\n",
    "    # Concatenate\n",
    "    if len(probs_list) == 0:\n",
    "        # empty loader edge case\n",
    "        return {\n",
    "            \"pairwise_accuracy\": 0.0,\n",
    "            \"ece\": 0.0,\n",
    "            \"acc_by_risk\": {},\n",
    "            \"ece_detail\": {\n",
    "                \"bin_edges\": np.linspace(0.0, 1.0, bins + 1),\n",
    "                \"bin_counts\": np.zeros(bins, dtype=int),\n",
    "                \"bin_acc\": np.zeros(bins, dtype=float),\n",
    "                \"bin_conf\": np.zeros(bins, dtype=float),\n",
    "            },\n",
    "            \"deltas\": np.array([], dtype=np.float32),\n",
    "            \"probs\": np.array([], dtype=np.float32),\n",
    "            \"corrects\": np.array([], dtype=np.float32),\n",
    "        }\n",
    "    \n",
    "    deltas = np.concatenate(deltas_list).astype(np.float32)   # (N,)\n",
    "    probs = np.concatenate(probs_list).astype(np.float32)     # (N,)\n",
    "    corrects = np.concatenate(corrects_list).astype(np.float32)  # (N,)\n",
    "    N = probs.shape[0]\n",
    "\n",
    "    # Pairwise accuracy\n",
    "    pairwise_acc = float(corrects.mean()) if N > 0 else 0.0\n",
    "\n",
    "    # ECE bins (equal-width on [0,1])\n",
    "    edges = np.linspace(0.0, 1.0, bins + 1)  # (bins+1,)\n",
    "    # Map probs in [0,1] to bin ids 0..bins-1\n",
    "    bin_ids = np.minimum((probs * bins).astype(int), bins - 1)\n",
    "\n",
    "    bin_counts = np.bincount(bin_ids, minlength=bins).astype(np.int64)\n",
    "    bin_correct_sum = np.bincount(bin_ids, weights=corrects, minlength=bins).astype(np.float64)\n",
    "    bin_conf_sum = np.bincount(bin_ids, weights=probs, minlength=bins).astype(np.float64)\n",
    "\n",
    "    # Averages per bin; avoid divide-by-zero\n",
    "    bin_acc = np.divide(\n",
    "        bin_correct_sum, bin_counts,\n",
    "        out=np.zeros_like(bin_correct_sum, dtype=np.float64),\n",
    "        where=bin_counts > 0\n",
    "    )\n",
    "    bin_conf = np.divide(\n",
    "        bin_conf_sum, bin_counts,\n",
    "        out=np.zeros_like(bin_conf_sum, dtype=np.float64),\n",
    "        where=bin_counts > 0\n",
    "    )\n",
    "\n",
    "    nonempty = bin_counts > 0\n",
    "    ece = float(np.sum((bin_counts[nonempty] / max(N, 1)) * np.abs(bin_acc[nonempty] - bin_conf[nonempty])))\n",
    "\n",
    "    # Accuracy by risk level\n",
    "    acc_by_risk = {}\n",
    "    if len(risks_all) == N and N > 0:\n",
    "        # Handle mixed types by unique() on array of objects\n",
    "        unique_risks = sorted(set(risks_all), key=lambda x: str(x))\n",
    "        for r in unique_risks:\n",
    "            idx = np.fromiter((rr == r for rr in risks_all), dtype=bool, count=N)\n",
    "            if idx.any():\n",
    "                acc_by_risk[r] = float(corrects[idx].mean())\n",
    "\n",
    "    return {\n",
    "        \"pairwise_accuracy\": pairwise_acc,\n",
    "        \"ece\": ece,\n",
    "        \"acc_by_risk\": acc_by_risk,\n",
    "        \"ece_detail\": {\n",
    "            \"bin_edges\": edges,\n",
    "            \"bin_counts\": bin_counts,\n",
    "            \"bin_acc\": bin_acc,\n",
    "            \"bin_conf\": bin_conf,\n",
    "        },\n",
    "        \"deltas\": deltas,\n",
    "        \"probs\": probs,\n",
    "        \"corrects\": corrects,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d48f60",
   "metadata": {},
   "source": [
    "## Saving/logging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f84b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(model, sub=\"epoch\"): # sub: subdirectory name\n",
    "    out = CKPT_DIR / sub\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    tokenizer.save_pretrained(out); model.save_pretrained(out)\n",
    "    print(f\"[saved] {out}\")\n",
    "\n",
    "def log_train_step(step:int, loss:float, epoch:int):\n",
    "    with TRAIN_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\"ts\": time.time(), \"step\": step, \"epoch\": epoch, \"loss\": float(loss)}) + \"\\n\")\n",
    "\n",
    "def log_val_epoch(epoch:int, metrics:dict):\n",
    "    rec = {\"ts\": time.time(), \"epoch\": epoch, **metrics}\n",
    "    with VAL_EPOCH_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "def dump_val_deltas(epoch:int, deltas:list[float]):\n",
    "    out = VAL_DELTAS_DIR / f\"deltas_epoch{epoch:02d}.json\"\n",
    "    out.write_text(json.dumps({\"epoch\": epoch, \"deltas\": deltas}), encoding=\"utf-8\")\n",
    "    return out\n",
    "\n",
    "def save_metrics(d: dict, name: str):\n",
    "    p = METRIC_DIR / name\n",
    "    p.write_text(json.dumps(d, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"[saved] {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c91a0",
   "metadata": {},
   "source": [
    "# 5. Training & Evaluation <a id='train-eval'></a>\n",
    "Training loop, evaluation metrics, checkpoints, and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6832b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser & AMP (automatic mixed precision) setup\n",
    "optim = AdamW(reward_model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "scaler = torch.amp.GradScaler(enabled=use_cuda)\n",
    "\n",
    "# Early stopping targets: maximise pairwise accuracy, minimise ECE\n",
    "patience, since_best = 2, 0\n",
    "best_score = (-1.0, float(\"inf\"))\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    reward_model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"epoch {epoch}\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "\n",
    "        # autocast only on CUDA\n",
    "        ctx = (torch.amp.autocast(device_type='cuda', enabled=True) if use_cuda\n",
    "               else contextlib.nullcontext())  # disable on CPU\n",
    "        with ctx:\n",
    "            # Pairwise Bradley-Terry (logistic) loss\n",
    "            loss, _ = step_batch(reward_model, batch) # returns (loss, delta_cpu)\n",
    "        \n",
    "        # backprop with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # unscale before clipping so clipping is applied on real magnitudes\n",
    "        scaler.unscale_(optim)\n",
    "        torch.nn.utils.clip_grad_norm_(reward_model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        # optimiser step through the scaler, then update scale for next iteration\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "\n",
    "        # logging per step\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        global_step += 1\n",
    "        log_train_step(global_step, loss.item(), epoch)\n",
    "\n",
    "    # Validation & compute metrics\n",
    "    val_metrics = evaluate_riskwise(reward_model, val_loader, bins=10)\n",
    "    all_deltas = val_metrics[\"deltas\"] # for histograms\n",
    "    save_metrics(val_metrics, f\"reward_eval_val_epoch{epoch:02d}.json\")\n",
    "    log_val_epoch(epoch, val_metrics)\n",
    "    dump_val_deltas(epoch, all_deltas)\n",
    "    print(f\"val (epoch {epoch}): {val_metrics['pairwise_accuracy']:.4f}, ECE={val_metrics['ece']:.4f}\")\n",
    "\n",
    "    # Model selection & early stopping\n",
    "    # Prefer higher accuracy and lower ECE; compare via (acc, -ece)\n",
    "    score = (val_metrics[\"pairwise_accuracy\"], -val_metrics[\"ece\"])\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        save_ckpt(reward_model, sub=\"best\")\n",
    "        since_best = 0\n",
    "    else:\n",
    "        since_best += 1\n",
    "        if since_best >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Always keep a per-epoch checkpoint for traceability\n",
    "    save_ckpt(reward_model, sub=f\"epoch{epoch:02d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25406e53",
   "metadata": {},
   "source": [
    "# 6. Visualisations <a id='viz'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d4237",
   "metadata": {},
   "source": [
    "## Training Loss by Steps (Smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, losses = [], []\n",
    "with open(METRIC_DIR / \"train_steps.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        steps.append(int(rec[\"step\"]))\n",
    "        losses.append(float(rec[\"loss\"]))\n",
    "\n",
    "# inline moving average\n",
    "def _moving_avg(x, w=50):\n",
    "    if len(x) < w: \n",
    "        return np.array(x, dtype=float)\n",
    "    c = np.cumsum(np.insert(x, 0, 0.0))\n",
    "    return (c[w:] - c[:-w]) / float(w)\n",
    "\n",
    "sm = _moving_avg(losses, w=50)\n",
    "xs = np.linspace(min(steps), max(steps), num=len(sm))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(xs, sm, label=\"Train Loss (smoothed)\")\n",
    "plt.title(\"Training Loss (by step, moving avg)\")\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = METRIC_DIR / \"train_loss_by_step.png\"\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e44eb",
   "metadata": {},
   "source": [
    "## Training VS Validation Loss by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67df526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate train loss per epoch from JSONL\n",
    "epoch_sum, epoch_cnt = {}, {}\n",
    "with open(METRIC_DIR / \"train_steps.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        ep, loss = int(rec[\"epoch\"]), float(rec[\"loss\"])\n",
    "        epoch_sum[ep] = epoch_sum.get(ep, 0.0) + loss\n",
    "        epoch_cnt[ep] = epoch_cnt.get(ep, 0) + 1\n",
    "\n",
    "train_epochs = sorted(epoch_sum.keys())\n",
    "train_epoch_loss = [epoch_sum[ep] / epoch_cnt[ep] for ep in train_epochs] # average loss per epoch\n",
    "\n",
    "# Load validation (use real val_loss if logged; else proxy from accuracy)\n",
    "val_epochs, val_losses = [], []\n",
    "for jpath in sorted(METRIC_DIR.glob(\"reward_eval_val_epoch*.json\")):\n",
    "    with open(jpath, \"r\", encoding=\"utf-8\") as f:\n",
    "        rec = json.load(f)\n",
    "    ep = int(jpath.stem.split(\"epoch\")[-1])\n",
    "    if \"val_loss\" in rec:\n",
    "        vloss = float(rec[\"val_loss\"])\n",
    "    else:\n",
    "        # proxy if didn't log val loss\n",
    "        vloss = 1.0 - float(rec[\"pairwise_accuracy\"])\n",
    "    val_epochs.append(ep)\n",
    "    val_losses.append(vloss)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(train_epochs, train_epoch_loss, \"o-\", label=\"Train Loss (per epoch)\")\n",
    "if val_losses:\n",
    "    plt.plot(val_epochs, val_losses, \"o-\", label=\"Validation Loss\", alpha=0.9)\n",
    "plt.title(\"Train vs Validation Loss (per epoch)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = METRIC_DIR / \"train_val_loss_by_epoch.png\"\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8b5fa",
   "metadata": {},
   "source": [
    "## Validation Pairwaise Accuracy & ECE (By Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, accs, eces = [], [], []\n",
    "with open(METRIC_DIR / \"val_epochs.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        epochs.append(rec[\"epoch\"])\n",
    "        accs.append(rec[\"pairwise_accuracy\"])\n",
    "        eces.append(rec[\"ece\"])\n",
    "\n",
    "# Validation pairwise accuracy by epoch\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, accs, marker=\"o\", color=\"tab:blue\")\n",
    "plt.title(\"Validation Pairwise Accuracy by Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(epochs)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = METRIC_DIR / \"val_accuracy_by_epoch.png\"\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved: {save_path}\")\n",
    "\n",
    "# Validation ECE by epoch\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, eces, marker=\"o\", color=\"tab:orange\")\n",
    "plt.title(\"Validation Calibration (ECE, 10 bins)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ECE\")\n",
    "plt.xticks(epochs)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = METRIC_DIR / \"val_ece_by_epoch.png\"\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445de12e",
   "metadata": {},
   "source": [
    "## Accuracy by Risk (Latest Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ff2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the latest epoch record\n",
    "last = None\n",
    "with open(METRIC_DIR / \"val_epochs.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        last = json.loads(line)\n",
    "\n",
    "if last is None:\n",
    "    raise ValueError(\"No validation record found in val_epochs.jsonl.\")\n",
    "\n",
    "# Extract accuracy by risk bins (dict of risk_bin -> accuracy)\n",
    "acc_by_risk = last.get(\"acc_by_risk\", {})\n",
    "labels = list(acc_by_risk.keys())\n",
    "vals = [acc_by_risk[k] for k in labels]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels, vals, color=\"tab:blue\", alpha=0.8)\n",
    "plt.title(f\"Accuracy by Risk (Epoch {last['epoch']})\")\n",
    "plt.xlabel(\"Risk Bin\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = METRIC_DIR / f\"accuracy_by_risk_epoch{last['epoch']:02d}.png\"\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4cffde",
   "metadata": {},
   "source": [
    "## Validation Œî = r_pos - r_neg Histogram (Latest Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest delta file\n",
    "delta_files = sorted(glob.glob(str(VAL_DELTAS_DIR / \"deltas_epoch*.json\")))\n",
    "if not delta_files:\n",
    "    raise FileNotFoundError(f\"No delta files found in: {VAL_DELTAS_DIR}\")\n",
    "\n",
    "with open(delta_files[-1], \"r\", encoding=\"utf-8\") as f:\n",
    "    rec = json.load(f)\n",
    "\n",
    "deltas = rec.get(\"deltas\", [])\n",
    "epoch = rec.get(\"epoch\", \"unknown\")\n",
    "\n",
    "# Plot histogram of Œî margins\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(deltas, bins=50, color=\"tab:purple\", alpha=0.75, edgecolor=\"black\")\n",
    "plt.title(f\"Validation Œî = r_pos - r_neg (Epoch {epoch})\")\n",
    "plt.xlabel(\"Œî margin (r_pos - r_neg)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = METRIC_DIR / f\"val_deltas_hist_epoch{epoch:02d}.png\"\n",
    "plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
